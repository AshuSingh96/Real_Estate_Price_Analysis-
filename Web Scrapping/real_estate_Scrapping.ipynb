{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver(headless_mode):\n",
    "    \"\"\"Setup the Chrome WebDriver with optional headless mode.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    if headless_mode:\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU hardware acceleration\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "    chrome_options.add_argument(\n",
    "        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36')\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the output CSV file name:  newdatacheck\n",
      "Enter the number of pages to scrape:  1\n",
      "Enter 'headless' for headless mode, or press Enter for standard mode:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1, found 41 elements\n",
      "Error processing element: list index out of range\n",
      "Error processing element: list index out of range\n",
      "Page 1 data saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_square_yards_data(output_file, max_pages, headless_mode=True):\n",
    "    driver = setup_driver(headless_mode)\n",
    "\n",
    "    driver.maximize_window()\n",
    "    url = 'https://www.squareyards.com/sale/property-for-sale-in-bangalore'\n",
    "    driver.get(url)\n",
    "\n",
    "    property_type = []\n",
    "    address = []\n",
    "    price_range = []\n",
    "    total_area = []\n",
    "    all_features = []\n",
    "    listing_type = []\n",
    "    amenities = []\n",
    "    project_info_text = []\n",
    "    price = []\n",
    "\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        driver.get(f\"https://www.squareyards.com/sale/property-for-sale-in-bangalore?page={page_num}\")\n",
    "        time.sleep(np.random.randint(4, 5))  # Random delay to avoid detection\n",
    "        \n",
    "        elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'dseprojectdata') and contains(@class, 'tileNo_')]\")\n",
    "        print(f\"Scraping page {page_num}, found {len(elements)} elements\")\n",
    "        \n",
    "        for element in elements:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "                time.sleep(np.random.uniform(1, 2))  # Small delay for stability\n",
    "                element.click()\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "                # Retrieve price\n",
    "                price_element = WebDriverWait(driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"/html/body/div[4]/div[2]/div[1]/div[2]/div[1]/strong\"))\n",
    "                )\n",
    "                price.append(price_element.text)\n",
    "\n",
    "                # Retrieve project information\n",
    "                project_info_element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"projectInformation\"))\n",
    "                )\n",
    "                project_info_text.append(project_info_element.text)\n",
    "\n",
    "                # Retrieve amenities\n",
    "                amenities_elements = driver.find_elements(By.XPATH, \"/html/body/div[6]/div/div/div[1]/div[3]/div[2]/div/table\")\n",
    "                amenities_text = \", \".join([amenity.text for amenity in amenities_elements]) if amenities_elements else \"No amenities found\"\n",
    "                amenities.append(amenities_text)\n",
    "\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing element: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Write data to CSV after each page\n",
    "        mode = 'a' if page_num > 1 else 'w'\n",
    "        with open(output_file, mode, newline='', encoding=\"utf-8\") as csvfile:\n",
    "            fieldnames = ['price', 'project_info_text', 'amenities']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            if mode == 'w':\n",
    "                writer.writeheader()\n",
    "            for i in range(len(price)):\n",
    "                writer.writerow({\n",
    "                    'price': price[i],\n",
    "                    'project_info_text': project_info_text[i],\n",
    "                    'amenities': amenities[i]\n",
    "                })\n",
    "        \n",
    "        print(f\"Page {page_num} data saved\")\n",
    "\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scraper\n",
    "output_file = input(\"Enter the output CSV file name: \") + \".csv\"\n",
    "max_pages = int(input(\"Enter the number of pages to scrape: \"))\n",
    "browser_mode = input(\"Enter 'headless' for headless mode, or press Enter for standard mode: \")\n",
    "headless_mode = True if browser_mode.lower() == 'headless' else False\n",
    "\n",
    "scrape_square_yards_data(output_file, max_pages, headless_mode)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
